{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sicelib.hammers import get_region_labels, SIM_SUBSET\n",
    "from collections import namedtuple\n",
    "import re\n",
    "import os\n",
    "import scipy\n",
    "import networkx\n",
    "import itertools\n",
    "import nilearn\n",
    "import nibabel\n",
    "from scipy import ndimage as ndi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and normalise the structural connectivity matrices\n",
    "=======================================================\n",
    "\n",
    "The matrices are represented as an (n×m×m) array, where n is the number of subjects and m is the number of regions.  We normalise by dividing each element by the corresponding row plus column sums, and take a submatrix by deleting those rows which are not in our subset of 62 regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "structural_connectivities = load(\"../classes/all/structural_connectivity.npy\")\n",
    "for sc in structural_connectivities:\n",
    "    region_sums = np.sum(sc, axis=0)\n",
    "    norm_matrix = region_sums[:, None] + region_sums\n",
    "    norm_matrix[norm_matrix == 0] = 1\n",
    "    sc /= norm_matrix\n",
    "structural_connectivities = structural_connectivities[:, SIM_SUBSET, :][:, :, SIM_SUBSET]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A helper function to turn one structural connectivity matrix into a list of thresholded matrices, such that the first element is a network without structural connections, the second contains only the strongest structural connection, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def threshold_matrix(matrix):\n",
    "    thresholds = unique(matrix[triu_indices_from(matrix, 1)].flatten())\n",
    "    thresholds[::-1].sort()\n",
    "    thresholded_matrices = []\n",
    "    for threshold in thresholds:\n",
    "        m = matrix.copy()\n",
    "        m[m < threshold] = 0\n",
    "        thresholded_matrices.append(m)\n",
    "    return thresholded_matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the metabolic connectivity matrices\n",
    "========================================\n",
    "\n",
    "Metabolic connectivity is estimated for the entire population as a whole.  We have obtained it for the actual data as well as 100 bootstrapped samples.  Each of these metabolic networks is represented as an (k×m×m) array, where m is the number of regions again, and k is the sparsity level (such that the kth matrix contains only the k strongest metabolic connections)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "metabolic_dir = \"results\"\n",
    "filename_re = re.compile(r\"all_zero_simhammers(?:_bootstrap(\\d|\\d\\d|100))?\\.pkl$\")\n",
    "metabolic_files = []\n",
    "for filename in os.listdir(metabolic_dir):\n",
    "    mt = filename_re.match(filename)\n",
    "    if mt:\n",
    "        bootstrap_seed = None\n",
    "        path = os.path.join(metabolic_dir, filename)\n",
    "        if mt.group(1) is not None:\n",
    "            bootstrap_seed = int(mt.group(1))\n",
    "            metabolic_files.append((path, bootstrap_seed))\n",
    "        else:\n",
    "            metabolic_files.insert(0, (path, None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This flag specifies whether or not negative correlations should be included in the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "negative_metabolic_connections = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network similarity analysis\n",
    "===========================\n",
    "\n",
    "This follows the procedure by Gong et al., Convergence and divergence of thickness correlations with diffusion connections across the human cerebral cortex, NeuroImage 59:1239-1248, 2012."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GongSimilarity = namedtuple(\"GongSimilarity\", [\"narcs\", \"similarity\", \"convergence\"])\n",
    "\n",
    "def compute_gong_similarity(structural_matrix, metabolic_matrices):\n",
    "    structural_matrices = threshold_matrix(structural_matrix)\n",
    "    possible_structural_narcs = [count_nonzero(sm[triu_indices_from(sm)]) for sm in structural_matrices]\n",
    "    possible_metabolic_narcs = [count_nonzero(mm[triu_indices_from(mm)]) for mm in metabolic_matrices]\n",
    "    narcs = intersect1d(possible_structural_narcs, possible_metabolic_narcs)\n",
    "    narcs = setdiff1d(narcs, [0])\n",
    "\n",
    "    accs = zeros(len(narcs))\n",
    "    convs = zeros(len(narcs))\n",
    "\n",
    "    for i, narc in enumerate(narcs):\n",
    "        struct_index = possible_structural_narcs.index(narc)\n",
    "        metabolic_index = possible_metabolic_narcs.index(narc)\n",
    "\n",
    "        s = structural_matrices[struct_index] != 0\n",
    "        s = s[triu_indices_from(s, 1)].flatten()\n",
    "\n",
    "        m = metabolic_matrices[metabolic_index] != 0\n",
    "        m = m[triu_indices_from(m, 1)].flatten()\n",
    "\n",
    "        fp = count_nonzero(m & ~s)\n",
    "        tn = count_nonzero(~m & ~s)\n",
    "\n",
    "        tp = count_nonzero(m & s)\n",
    "        fn = count_nonzero(~m & s)\n",
    "\n",
    "        accs[i] = (tn + tp) / (tn + fn + fp + tp)\n",
    "        convs[i] = count_nonzero(s & m) / narc\n",
    "        \n",
    "    return GongSimilarity(narcs=narcs, similarity=accs, convergence=convs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the similarity scores on the real data and the bootstrap samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "narcs = arange(450) + 1\n",
    "data_similarities = zeros((len(metabolic_files), len(narcs)))\n",
    "data_convergences = zeros((len(metabolic_files), len(narcs)))\n",
    "\n",
    "for i, (filename, bootstrap_seed) in enumerate(metabolic_files):\n",
    "    if bootstrap_seed is not None:\n",
    "        index_sequence = np.random.RandomState(bootstrap_seed). \\\n",
    "            choice(len(structural_connectivities),\n",
    "                   size=len(structural_connectivities),\n",
    "                   replace=True)\n",
    "    else:\n",
    "        index_sequence = arange(len(structural_connectivities))\n",
    "    structural_matrix = np.mean(structural_connectivities[index_sequence], axis=0)\n",
    "    metabolic_data = load(filename)\n",
    "    if negative_metabolic_connections:\n",
    "        metabolic_matrices = array(metabolic_data[\"prec\"]) != 0\n",
    "    else:\n",
    "        metabolic_matrices = array(metabolic_data[\"prec\"]) < 0\n",
    "    gong_similarity = compute_gong_similarity(structural_matrix,\n",
    "                                              metabolic_matrices)\n",
    "    data_similarities[i] = scipy.interp(narcs, gong_similarity.narcs,\n",
    "                                        gong_similarity.similarity)\n",
    "    data_convergences[i] = scipy.interp(narcs, gong_similarity.narcs,\n",
    "                                        gong_similarity.convergence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a set of independently randomly generated metabolic and structural networks to establish reference scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_chance_runs = 100\n",
    "chance_similarities = zeros((n_chance_runs, len(narcs)))\n",
    "chance_convergences = zeros((n_chance_runs, len(narcs)))\n",
    "max_narcs = narcs[-1]\n",
    "n_regions = len(SIM_SUBSET)\n",
    "\n",
    "for i in range(n_chance_runs):\n",
    "    triu_size = n_regions * (n_regions - 1) // 2\n",
    "    x = concatenate([arange(max_narcs) + 1, zeros(triu_size - max_narcs)])\n",
    "    \n",
    "    shuffle(x)\n",
    "    chance_metabolic = zeros((n_regions, n_regions))\n",
    "    chance_metabolic[triu_indices_from(chance_metabolic, 1)] = x\n",
    "    chance_metabolic += chance_metabolic.T\n",
    "\n",
    "    shuffle(x)\n",
    "    chance_structural = zeros((n_regions, n_regions))\n",
    "    chance_structural[triu_indices_from(chance_structural, 1)] = x\n",
    "    chance_structural += chance_structural.T\n",
    "    \n",
    "    gong_similarity = compute_gong_similarity(chance_structural,\n",
    "                                              threshold_matrix(chance_metabolic))\n",
    "    chance_similarities[i] = gong_similarity.similarity\n",
    "    chance_convergences[i] = gong_similarity.convergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the whole thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "figsize(10, 5)\n",
    "subplot(1, 2, 1)\n",
    "bs_mean_curve, = plot(narcs, mean(data_similarities, axis=0), \"b\")\n",
    "plot(narcs, mean(data_similarities, axis=0) + std(data_similarities, axis=0), \"b--\")\n",
    "plot(narcs, mean(data_similarities, axis=0) - std(data_similarities, axis=0), \"b--\")\n",
    "real_curve, = plot(narcs, data_similarities[0], \"r\")\n",
    "chance_curve, = plot(narcs, mean(chance_similarities, axis=0), \"k\")\n",
    "plot(narcs, mean(chance_similarities, axis=0) + std(chance_similarities, axis=0), \"k--\")\n",
    "plot(narcs, mean(chance_similarities, axis=0) - std(chance_similarities, axis=0), \"k--\")\n",
    "xlim(50, 400)\n",
    "ylim(0.6, 1)\n",
    "xlabel(\"Number of connections\", fontsize=12)\n",
    "ylabel(\"Similarity metric\", fontsize=12)\n",
    "legend([real_curve, bs_mean_curve, chance_curve],\n",
    "       [\"real network\", \"bootstrapped real networks (μ ± σ)\", \"random networks (μ ± σ)\"],\n",
    "       loc=\"lower left\")\n",
    "grid()\n",
    "\n",
    "subplot(1, 2, 2)\n",
    "plot(narcs, mean(data_convergences, axis=0), \"b\")\n",
    "plot(narcs, mean(data_convergences, axis=0) + std(data_convergences, axis=0), \"b--\")\n",
    "plot(narcs, mean(data_convergences, axis=0) - std(data_convergences, axis=0), \"b--\")\n",
    "plot(narcs, data_convergences[0], \"r\")\n",
    "plot(narcs, mean(chance_convergences, axis=0), \"k\")\n",
    "plot(narcs, mean(chance_convergences, axis=0) + std(chance_convergences, axis=0), \"k--\")\n",
    "plot(narcs, mean(chance_convergences, axis=0) - std(chance_convergences, axis=0), \"k--\")\n",
    "xlim(50, 400)\n",
    "ylim(0, 0.8)\n",
    "xlabel(\"Number of connections\", fontsize=12)\n",
    "ylabel(\"Convergence ratio\", fontsize=12)\n",
    "grid()\n",
    "\n",
    "suptitle(\"Metabolic and structural connectivity networks\", fontsize=14)\n",
    "tight_layout(rect=[0, 0, 1, 0.95])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Efficiency analysis\n",
    "===================\n",
    "\n",
    "Compare some structural properties of the graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def distance_matrix(g):\n",
    "    dist_dict = networkx.all_pairs_shortest_path_length(g)\n",
    "    dist = numpy.full((len(g), len(g)), inf)\n",
    "    for i, v in enumerate(g):\n",
    "        if v not in dist_dict: continue\n",
    "        for j, w in enumerate(g):\n",
    "            if w not in dist_dict[v]: continue\n",
    "            dist[i, j] = dist_dict[v][w]\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NetworkMeasures = namedtuple(\"NetworkMeasures\", [\"narcs\", \"global_efficiencies\", \"local_efficiencies\"])\n",
    "\n",
    "def compute_network_measures(matrices):\n",
    "    if type(matrices) is ndarray and matrices.ndim == 2:\n",
    "        matrices = threshold_matrix(matrices)\n",
    "\n",
    "    local_efficiencies = []\n",
    "    global_efficiencies = []\n",
    "    narcs = []\n",
    "\n",
    "    for matrix in matrices:\n",
    "        if type(matrix) is not networkx.Graph:\n",
    "            g = networkx.Graph(matrix != 0)\n",
    "        else:\n",
    "            g = matrix\n",
    "        dist_dict = networkx.all_pairs_shortest_path_length(g)\n",
    "        dist = full((len(g), len(g)), inf)\n",
    "        for i in dist_dict.keys():\n",
    "            for j in dist_dict[i].keys():\n",
    "                dist[i, j] = dist_dict[i][j]\n",
    "\n",
    "        narcs.append(g.size())\n",
    "        global_efficiencies.append((1 / dist[triu_indices_from(dist, 1)]).mean())\n",
    "\n",
    "        le = []\n",
    "        for v in g:\n",
    "            g_sub = g.subgraph(g[v])\n",
    "            if len(g_sub) <= 1:\n",
    "                le.append(0)\n",
    "                continue\n",
    "            sub_dist_dict = networkx.all_pairs_shortest_path_length(g_sub)\n",
    "            sub_dist = full((len(g_sub), len(g_sub)), inf)\n",
    "            vertex_map = {w: i for i, w in enumerate(g_sub.nodes())}\n",
    "            for i in sub_dist_dict.keys():\n",
    "                for j in sub_dist_dict[i].keys():\n",
    "                    sub_dist[vertex_map[i], vertex_map[j]] = sub_dist_dict[i][j]\n",
    "            le.append((1 / sub_dist[triu_indices_from(sub_dist, 1)]).mean())\n",
    "\n",
    "        local_efficiencies.append(mean(le))\n",
    "        \n",
    "    order = argsort(narcs)\n",
    "        \n",
    "    return NetworkMeasures(narcs=np.array(narcs)[order],\n",
    "                           global_efficiencies=np.array(global_efficiencies)[order],\n",
    "                           local_efficiencies=np.array(local_efficiencies)[order])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Individually compute local and global efficiency scores for the structural and metabolic networks, for the real data and the bootstrapped samples.  This takes a good while; you may want to put a “break” at the end of the loop to skip the bootstrapped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "narcs = arange(450) + 1\n",
    "data_met_local_efficiencies = zeros((len(metabolic_files), len(narcs)))\n",
    "data_met_global_efficiencies = zeros((len(metabolic_files), len(narcs)))\n",
    "data_struct_local_efficiencies = zeros((len(metabolic_files), len(narcs)))\n",
    "data_struct_global_efficiencies = zeros((len(metabolic_files), len(narcs)))\n",
    "\n",
    "for i, (filename, bootstrap_seed) in enumerate(metabolic_files):\n",
    "    if bootstrap_seed is not None:\n",
    "        index_sequence = np.random.RandomState(bootstrap_seed). \\\n",
    "            choice(len(structural_connectivities),\n",
    "                   size=len(structural_connectivities),\n",
    "                   replace=True)\n",
    "    else:\n",
    "        index_sequence = arange(len(structural_connectivities))\n",
    "    structural_matrix = np.mean(structural_connectivities[index_sequence], axis=0)\n",
    "    metabolic_data = load(filename)\n",
    "    if negative_metabolic_connections:\n",
    "        metabolic_matrices = array(metabolic_data[\"prec\"]) != 0\n",
    "    else:\n",
    "        metabolic_matrices = array(metabolic_data[\"prec\"]) < 0\n",
    "    data_met_network_measures = compute_network_measures(metabolic_matrices)\n",
    "    data_met_local_efficiencies[i] = scipy.interp(narcs, data_met_network_measures.narcs,\n",
    "                                                  data_met_network_measures.local_efficiencies)\n",
    "    data_met_global_efficiencies[i] = scipy.interp(narcs, data_met_network_measures.narcs,\n",
    "                                                   data_met_network_measures.global_efficiencies)\n",
    "    data_struct_network_measures = compute_network_measures(structural_matrix)\n",
    "    data_struct_local_efficiencies[i] = scipy.interp(narcs, data_struct_network_measures.narcs,\n",
    "                                                     data_struct_network_measures.local_efficiencies)\n",
    "    data_struct_global_efficiencies[i] = scipy.interp(narcs, data_struct_network_measures.narcs,\n",
    "                                                      data_struct_network_measures.global_efficiencies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function creates a random, but comparable graph to an input, in that they have the same degree distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def random_rewire(graph):\n",
    "    graph = graph.copy()\n",
    "    for iteration in range(graph.size()):\n",
    "        e = graph.edges()\n",
    "        while True:\n",
    "            i1, i2 = np.random.choice(arange(len(e)), size=2, replace=False)\n",
    "            e1, e2 = e[i1], e[i2]\n",
    "            new_e1 = e1[0], e2[1]\n",
    "            new_e2 = e1[1], e2[0]\n",
    "            if new_e1[0] != new_e1[1] and new_e2[0] != new_e2[1] and \\\n",
    "                    not graph.has_edge(*new_e1) and not graph.has_edge(*new_e2):\n",
    "                break\n",
    "        graph.remove_edge(*e1)\n",
    "        graph.remove_edge(*e2)\n",
    "        graph.add_edge(*new_e1)\n",
    "        graph.add_edge(*new_e2)\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the computation again for some of these randomly rewired graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_chance_runs = 100\n",
    "chance_met_local_efficiencies = zeros((n_chance_runs, len(narcs)))\n",
    "chance_met_global_efficiencies = zeros((n_chance_runs, len(narcs)))\n",
    "chance_struct_local_efficiencies = zeros((n_chance_runs, len(narcs)))\n",
    "chance_struct_global_efficiencies = zeros((n_chance_runs, len(narcs)))\n",
    "\n",
    "# the randomly rewired graphs are modelled after the real (non-bootstrapped) data\n",
    "metabolic_data = load(metabolic_files[0][0])\n",
    "if negative_metabolic_connections:\n",
    "    metabolic_matrices = array(metabolic_data[\"prec\"]) != 0\n",
    "else:\n",
    "    metabolic_matrices = array(metabolic_data[\"prec\"]) < 0\n",
    "for m in metabolic_matrices:\n",
    "    fill_diagonal(m, False)\n",
    "metabolic_graphs = [networkx.Graph(m) for m in metabolic_matrices if count_nonzero(m) // 2 >= 10]\n",
    "\n",
    "structural_matrix = np.mean(structural_connectivities, axis=0)\n",
    "structural_matrices = threshold_matrix(structural_matrix)\n",
    "structural_graphs = [networkx.Graph(m != 0) for m in structural_matrices if count_nonzero(m != 0) // 2 >= 10]\n",
    "\n",
    "for i in range(n_chance_runs):\n",
    "    print(\"{}/{}\".format(i + 1, n_chance_runs))\n",
    "    chance_met_network_measures = compute_network_measures([random_rewire(g) for g in metabolic_graphs])\n",
    "    chance_met_local_efficiencies[i] = scipy.interp(narcs, chance_met_network_measures.narcs,\n",
    "                                                    chance_met_network_measures.local_efficiencies)\n",
    "    chance_met_global_efficiencies[i] = scipy.interp(narcs, chance_met_network_measures.narcs,\n",
    "                                                     chance_met_network_measures.global_efficiencies)\n",
    "    chance_struct_network_measures = compute_network_measures([random_rewire(g) for g in structural_graphs])\n",
    "    chance_struct_local_efficiencies[i] = scipy.interp(narcs, chance_struct_network_measures.narcs,\n",
    "                                                       chance_struct_network_measures.local_efficiencies)\n",
    "    chance_struct_global_efficiencies[i] = scipy.interp(narcs, chance_struct_network_measures.narcs,\n",
    "                                                        chance_struct_network_measures.global_efficiencies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And plot the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "figsize(10, 10)\n",
    "titles = [\"Global efficiency of the metabolic network\",\n",
    "          \"Global efficiency of the structural network\",\n",
    "          \"Local efficiency of the metabolic network\",\n",
    "          \"Local efficiency of the structural network\"]\n",
    "for i, (de, ce) in enumerate([(data_met_global_efficiencies, chance_met_global_efficiencies),\n",
    "                              (data_struct_global_efficiencies, chance_struct_global_efficiencies),\n",
    "                              (data_met_local_efficiencies, chance_met_local_efficiencies),\n",
    "                              (data_struct_local_efficiencies, chance_struct_local_efficiencies)]):\n",
    "    subplot(2, 2, i+1)\n",
    "    title(titles[i])\n",
    "    bs_mean_curve, = plot(narcs, mean(de, axis=0), \"b\")\n",
    "    plot(narcs, mean(de, axis=0) + std(de, axis=0), \"b--\")\n",
    "    plot(narcs, mean(de, axis=0) - std(de, axis=0), \"b--\")\n",
    "    real_curve, = plot(narcs, de[0], \"r\")\n",
    "    chance_curve, = plot(narcs, mean(ce, axis=0), \"k\")\n",
    "    plot(narcs, mean(ce, axis=0) + std(ce, axis=0), \"k--\")\n",
    "    plot(narcs, mean(ce, axis=0) - std(ce, axis=0), \"k--\")\n",
    "    ylim(0, 0.8)\n",
    "    if i == 1:\n",
    "        legend([real_curve, bs_mean_curve, chance_curve],\n",
    "               [\"real network\", \"bootstrapped networks (μ ± σ)\", \"randomly rewired networks (μ ± σ)\"], loc=\"upper left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Structural and metabolic hubs\n",
    "=============================\n",
    "\n",
    "Again following Gong et al., for both the structural and metabolic networks, we consider vertices with a regional efficiency which exceeds the mean plus one standard deviation to be hubs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def regional_efficiencies(matrix):\n",
    "    g = networkx.Graph(matrix != 0)\n",
    "    dist = distance_matrix(g)\n",
    "    vertices = []\n",
    "    regional_efficiencies = []\n",
    "    for i, v in enumerate(g):\n",
    "        vertices.append(v)\n",
    "        local_dist = delete(delete(dist, i, axis=0), i, axis=1)\n",
    "        regional_efficiencies.append(mean(1 / local_dist[triu_indices_from(local_dist, 1)]))\n",
    "    regional_efficiencies = array(regional_efficiencies)\n",
    "    vertices = array(vertices)\n",
    "    regional_efficiencies -= mean(regional_efficiencies)\n",
    "    regional_efficiencies /= std(regional_efficiencies)\n",
    "    indices = argsort(regional_efficiencies)[::-1]\n",
    "    return zip(vertices[indices], regional_efficiencies[indices])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Work with the full, non-bootstrapped dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "metabolic_matrices = array(load(metabolic_files[0][0])[\"prec\"])\n",
    "if negative_metabolic_connections:\n",
    "    metabolic_matrices = metabolic_matrices != 0\n",
    "else:\n",
    "    metabolic_matrices = metabolic_matrices < 0\n",
    "structural_matrix = mean(structural_connectivities, axis=0)\n",
    "structural_matrices = threshold_matrix(structural_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the structural and metabolic matrices with a fixed number of strongest connections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_connections = 150\n",
    "metabolic_index = argmin(np.abs(n_connections - array([count_nonzero(m) for m in metabolic_matrices]) // 2))\n",
    "structural_index = argmin(np.abs(n_connections - array([count_nonzero(m) for m in structural_matrices]) // 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify the hubs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "metabolic_hubs = set(region_labels[i] for i, eff in regional_efficiencies(metabolic_matrices[metabolic_index]) if eff > 1)\n",
    "structural_hubs = set(region_labels[i] for i, eff in regional_efficiencies(structural_matrices[metabolic_index]) if eff > 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"\\n\".join(metabolic_hubs & structural_hubs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"\\n\".join(metabolic_hubs.difference(structural_hubs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"\\n\".join(structural_hubs.difference(metabolic_hubs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualisation of individual networks\n",
    "===================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define boolean matrices which are True for all connections between hemispheres (interhemispheric_mak), or between all homologous regional pairs (homologous_mask)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "region_labels = get_region_labels(SIM_SUBSET)\n",
    "left_regions, right_regions = array([[l.endswith(\"_L\"), l.endswith(\"_R\")] for l in region_labels]).T\n",
    "\n",
    "homologous_mask = zeros_like(structural_matrix, dtype=bool)\n",
    "homologous_mask[left_regions, right_regions] = True\n",
    "homologous_mask[right_regions, left_regions] = True\n",
    "\n",
    "interhemispheric_mask = zeros_like(structural_matrix, dtype=bool)\n",
    "for i, j in itertools.product(where(left_regions)[0], where(right_regions)[0]):\n",
    "    interhemispheric_mask[i, j] = interhemispheric_mask[j, i] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot convergent and divergent connections as a matrix…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "figsize(12, 10)\n",
    "convergence = 2 * metabolic_matrices[metabolic_index].astype(int) + (structural_matrices[structural_index] != 0).astype(int)\n",
    "imshow(convergence, interpolation=\"none\", cmap=cm.get_cmap(\"cubehelix_r\", 4))\n",
    "colorbar(ticks=[0, 1, 2, 3], format=FuncFormatter(lambda val, loc: {0: \"not connected\",\n",
    "                                                                    1: \"structural connection only\",\n",
    "                                                                    2: \"metabolic connection only\",\n",
    "                                                                    3: \"structural and metabolic connections\"}[val]),\n",
    "         shrink=0.5)\n",
    "clim(-0.5, 3.5)\n",
    "xticks(arange(len(region_labels)), region_labels, rotation=90);\n",
    "yticks(arange(len(region_labels)), region_labels);\n",
    "grid();\n",
    "tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the same information on a drawing of a brain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "atlas = nibabel.load(\"../../data/dti_ftlad/atlases/hammers/Hammers_mith_atlas_n30r83_SPM5.nii.gz\")\n",
    "atlas_data = atlas.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "centers_vox = ndi.center_of_mass(ones_like(atlas_data), atlas_data, SIM_SUBSET + 1)\n",
    "centers_vox_hom = hstack([array(centers_vox), ones((len(centers_vox), 1))])\n",
    "centers_mm_hom = atlas.affine.dot(centers_vox_hom.T).T\n",
    "centers_mm = centers_mm_hom[:, 0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = figure(figsize=(9, 3))\n",
    "nilearn.plotting.plot_connectome(convergence, centers_mm, edge_cmap=\"cubehelix_r\", edge_vmin=0, edge_vmax=3, figure=fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frequency of interhemispheric connections\n",
    "========================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metabolic_narcs = [count_nonzero(mm) // 2 for mm in metabolic_matrices]\n",
    "structural_narcs = [count_nonzero(sm) // 2 for sm in structural_matrices]\n",
    "narcs = intersect1d(metabolic_narcs, structural_narcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "interhemispheric = zeros((2, len(narcs)))\n",
    "homologous = zeros((2, len(narcs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, narc in enumerate(narcs):\n",
    "    mm = metabolic_matrices[metabolic_narcs.index(narc)]\n",
    "    sm = structural_matrices[structural_narcs.index(narc)]\n",
    "    interhemispheric[:, i] = [count_nonzero((m != 0) & interhemispheric_mask) / count_nonzero(m)\n",
    "                              for m in [mm, sm]]\n",
    "    homologous[:, i] = [count_nonzero((m != 0) & homologous_mask) / count_nonzero(m)\n",
    "                        for m in [mm, sm]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "figure(figsize=(10, 4))\n",
    "subplot(121)\n",
    "plot(interhemispheric.T)\n",
    "title(\"Prevalence of interhemispheric connections\")\n",
    "legend([\"metabolic network\", \"structural network\"])\n",
    "subplot(122)\n",
    "plot(homologous.T)\n",
    "title(\"Prevalence of homologous connections\")\n",
    "tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distances in the networks\n",
    "========================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gm_probability = nilearn.image.index_img(nibabel.load(\"/home/michael/software/spm12/tpm/TPM.nii\"), 0)\n",
    "gm_probability = nilearn.image.resample_img(gm_probability, atlas.affine, atlas.shape)\n",
    "atlas_data[gm_probability.get_data() < 0.8] = 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
