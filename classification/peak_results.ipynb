{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from glob import glob\n",
    "import os\n",
    "import pandas\n",
    "import sklearn.metrics\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_peak(result, scoring_function):\n",
    "    keys = sorted(result[0].keys())\n",
    "    guesses = [concatenate([fold[key][\"guesses\"] for fold in result]) for key in keys]\n",
    "    true_labels = concatenate([fold[keys[0]][\"true_labels\"] for fold in result])\n",
    "    scores = [scoring_function(true_labels, guess) for guess in guesses]\n",
    "    return keys[argmax(scores)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class0_recall = lambda gt, pred: sklearn.metrics.recall_score(gt, pred, pos_label=0)\n",
    "class1_recall = lambda gt, pred: sklearn.metrics.recall_score(gt, pred, pos_label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_scores(result, key):\n",
    "    guess = concatenate([fold[key][\"guesses\"] for fold in result])\n",
    "    true_labels = concatenate([fold[key][\"true_labels\"] for fold in result])\n",
    "    return {\n",
    "        \"accuracy\": sklearn.metrics.accuracy_score(true_labels, guess),\n",
    "        \"class0_recall\": class0_recall(true_labels, guess),\n",
    "        \"class1_recall\": class1_recall(true_labels, guess),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "run = \"adftld_0_0\"\n",
    "pattern = re.compile(r\"^.*_tfphammers$\")\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames = [fn for fn in glob(\"results/{}_*.csv\".format(run))\n",
    "             if pattern.match(os.path.basename(fn)[len(run) + 1:-4])]\n",
    "len(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for filename in filenames:\n",
    "    df = pandas.read_csv(filename, dtype={\"labels\": str})\n",
    "    data = []\n",
    "    for fold in df.fold.unique():\n",
    "        fold_df = df[df.fold == fold]\n",
    "        guess_df = fold_df[fold_df.param > 0].sort_values(\"param\")\n",
    "        ground_truth = [int(c) for c in fold_df[fold_df.param == 0][\"labels\"].as_matrix()[0]]\n",
    "        guesses = guess_df[\"labels\"].as_matrix()\n",
    "        params = guess_df[\"param\"].as_matrix()\n",
    "        narcs = guess_df[[\"narcs0\", \"narcs1\"]].as_matrix()\n",
    "        fold_data = {}\n",
    "        for param, guess, narcs in zip(params, guesses, narcs):\n",
    "            fold_data[param] = {\"true_labels\": ground_truth, \"guesses\": [int(c) for c in guess],\n",
    "                                \"narcs\": narcs}\n",
    "        data.append(fold_data)\n",
    "    method, _ = os.path.splitext(filename)\n",
    "    method = method.split(\"_\", 3)[3].replace(\"_compact\", \"\")\n",
    "    results[method] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "peak_accuracies = {k: find_peak(v, sklearn.metrics.accuracy_score) for k, v in results.items()}\n",
    "peak_class0_recalls = {k: find_peak(v, class0_recall) for k, v in results.items()}\n",
    "peak_class1_recalls = {k: find_peak(v, class1_recall) for k, v in results.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "method_groups = collections.defaultdict(list)\n",
    "for method in results.keys():\n",
    "    _, method_group = method.split(\"_\", 1)\n",
    "    method_groups[method_group].append(method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp0.05_fa_tfphammers                                 0.79    0.83    0.73\n",
      "pow3_fa_tfphammers                                    0.89    0.90    0.87\n",
      "pow1_fa_tfphammers                                    0.83    0.85    0.80\n",
      "exp0.4_fa_tfphammers                                  0.86    0.85    0.87\n",
      "pow2_fa_tfphammers                                    0.89    0.90    0.87\n",
      "exp0.1_fa_tfphammers                                  0.83    0.85    0.80\n",
      "exp1_fa_tfphammers                                    0.83    0.85    0.80\n",
      "exp0.8_fa_tfphammers                                  0.83    0.85    0.80\n",
      "exp0.2_fa_tfphammers                                  0.90    0.93    0.87\n",
      "exp0.01_fa_tfphammers                                 0.79    0.80    0.77\n",
      "exp0.02_fa_tfphammers                                 0.79    0.83    0.73\n",
      "\n",
      "pow3_tfphammers                                       0.85    0.85    0.83\n",
      "pow1_tfphammers                                       0.83    0.85    0.80\n",
      "exp1_tfphammers                                       0.83    0.85    0.80\n",
      "pow2_tfphammers                                       0.85    0.85    0.83\n",
      "exp0.2_tfphammers                                     0.85    0.85    0.83\n",
      "exp0.8_tfphammers                                     0.83    0.85    0.80\n",
      "exp0.4_tfphammers                                     0.85    0.85    0.83\n",
      "unweighted_tfphammers                                 0.85    0.88    0.80\n",
      "zero_tfphammers                                       0.82    0.85    0.77\n",
      "exp0.1_tfphammers                                     0.85    0.83    0.87\n",
      "exp0.01_tfphammers                                    0.89    0.90    0.87\n",
      "exp0.02_tfphammers                                    0.89    0.90    0.87\n",
      "exp0.05_tfphammers                                    0.85    0.85    0.83\n",
      "\n",
      "exp0.01_normsc_tfphammers                             0.83    0.83    0.83\n",
      "pow3_normsc_tfphammers                                0.86    0.85    0.87\n",
      "exp0.05_normsc_tfphammers                             0.87    0.90    0.83\n",
      "exp0.4_normsc_tfphammers                              0.85    0.85    0.83\n",
      "pow2_normsc_tfphammers                                0.86    0.88    0.83\n",
      "pow1_normsc_tfphammers                                0.83    0.85    0.80\n",
      "exp0.2_normsc_tfphammers                              0.87    0.88    0.87\n",
      "exp1_normsc_tfphammers                                0.83    0.85    0.80\n",
      "exp0.1_normsc_tfphammers                              0.89    0.90    0.87\n",
      "exp0.8_normsc_tfphammers                              0.83    0.85    0.80\n",
      "exp0.02_normsc_tfphammers                             0.85    0.85    0.83\n",
      "\n",
      "pow1_diff_normsc_tfphammers                           0.86    0.90    0.80\n",
      "pow3_diff_normsc_tfphammers                           0.86    0.90    0.80\n",
      "exp0.02_diff_normsc_tfphammers                        0.85    0.88    0.80\n",
      "exp0.01_diff_normsc_tfphammers                        0.83    0.88    0.77\n",
      "exp0.1_diff_normsc_tfphammers                         0.86    0.90    0.80\n",
      "exp0.8_diff_normsc_tfphammers                         0.85    0.85    0.83\n",
      "exp0.05_diff_normsc_tfphammers                        0.85    0.85    0.83\n",
      "pow2_diff_normsc_tfphammers                           0.86    0.90    0.80\n",
      "exp0.2_diff_normsc_tfphammers                         0.86    0.90    0.80\n",
      "exp1_diff_normsc_tfphammers                           0.83    0.85    0.80\n",
      "exp0.4_diff_normsc_tfphammers                         0.85    0.88    0.80\n",
      "\n",
      "pow2_diff_fa_tfphammers                               0.86    0.90    0.80\n",
      "pow1_diff_fa_tfphammers                               0.86    0.90    0.80\n",
      "exp1_diff_fa_tfphammers                               0.83    0.85    0.80\n",
      "exp0.4_diff_fa_tfphammers                             0.85    0.85    0.83\n",
      "exp0.1_diff_fa_tfphammers                             0.87    0.90    0.83\n",
      "pow3_diff_fa_tfphammers                               0.86    0.90    0.80\n",
      "exp0.05_diff_fa_tfphammers                            0.86    0.88    0.83\n",
      "exp0.2_diff_fa_tfphammers                             0.86    0.90    0.80\n",
      "exp0.01_diff_fa_tfphammers                            0.83    0.85    0.80\n",
      "exp0.02_diff_fa_tfphammers                            0.85    0.85    0.83\n",
      "exp0.8_diff_fa_tfphammers                             0.83    0.83    0.83\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for method_group, methods in method_groups.items():\n",
    "    for m in methods:\n",
    "        sc = calculate_scores(results[m], peak_accuracies[m])\n",
    "        print(\"{:<50}    {:.2f}    {:.2f}    {:.2f}\".format(m, sc[\"accuracy\"], sc[\"class0_recall\"], sc[\"class1_recall\"]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
